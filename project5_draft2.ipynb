{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b16e20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "83c7603e",
   "metadata": {},
   "source": [
    "# 1.1 Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f002695",
   "metadata": {},
   "source": [
    "# 1.2 Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36222ee2",
   "metadata": {},
   "source": [
    "# 2.1 Import library and data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2202663",
   "metadata": {},
   "source": [
    "import libeary that is used for the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2c1fdc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data analysis and wrangling\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "import math\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import stats as stats\n",
    "\n",
    "# visualization\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# scaling and train test split\n",
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# pipeline setup\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# cross validation\n",
    "from sklearn.model_selection import KFold\n",
    "# Import the evaluation matrics\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, plot_confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV,\\\n",
    "cross_val_score, RandomizedSearchCV\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.metrics import accuracy_score, roc_curve, auc\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import tree\n",
    "\n",
    "# evaluation on test data\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error,explained_variance_score\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "# import library for Gradient Boosting\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b744ff",
   "metadata": {},
   "source": [
    "Read the data into a pandas dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "5ad57127",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_1 = ('\\\\Users\\\\eggfr\\\\Flatiron\\\\Flatiron_phase5_project\\\\data\\\\Auto_Train_Dataset.csv')\n",
    "file_path_2 = ('\\\\Users\\\\eggfr\\\\Flatiron\\\\Flatiron_phase5_project\\\\data\\\\Auto_Data_Dictionary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d7814f4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eggfr\\AppData\\Local\\Temp\\ipykernel_18944\\4212711854.py:1: DtypeWarning: Columns (1,7,8,16,17,18,19,20,35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  autoloan_raw_df = pd.read_csv(file_path_1,encoding='unicode_escape')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Client_Income</th>\n",
       "      <th>Car_Owned</th>\n",
       "      <th>Bike_Owned</th>\n",
       "      <th>Active_Loan</th>\n",
       "      <th>House_Own</th>\n",
       "      <th>Child_Count</th>\n",
       "      <th>Credit_Amount</th>\n",
       "      <th>Loan_Annuity</th>\n",
       "      <th>Accompany_Client</th>\n",
       "      <th>...</th>\n",
       "      <th>Client_Permanent_Match_Tag</th>\n",
       "      <th>Client_Contact_Work_Tag</th>\n",
       "      <th>Type_Organization</th>\n",
       "      <th>Score_Source_1</th>\n",
       "      <th>Score_Source_2</th>\n",
       "      <th>Score_Source_3</th>\n",
       "      <th>Social_Circle_Default</th>\n",
       "      <th>Phone_Change</th>\n",
       "      <th>Credit_Bureau</th>\n",
       "      <th>Default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12142509</td>\n",
       "      <td>6750</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>61190.55</td>\n",
       "      <td>3416.85</td>\n",
       "      <td>Alone</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.02</td>\n",
       "      <td>63.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12138936</td>\n",
       "      <td>20250</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>15282</td>\n",
       "      <td>1826.55</td>\n",
       "      <td>Alone</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Government</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12181264</td>\n",
       "      <td>18000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>59527.35</td>\n",
       "      <td>2788.2</td>\n",
       "      <td>Alone</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.07</td>\n",
       "      <td>277.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12188929</td>\n",
       "      <td>15750</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>53870.4</td>\n",
       "      <td>2295.45</td>\n",
       "      <td>Alone</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>XNA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1700.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12133385</td>\n",
       "      <td>33750</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>133988.4</td>\n",
       "      <td>3547.35</td>\n",
       "      <td>Alone</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Business Entity Type 3</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.20</td>\n",
       "      <td>674.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID Client_Income  Car_Owned  Bike_Owned  Active_Loan  House_Own  \\\n",
       "0  12142509          6750       0.00        0.00         1.00       0.00   \n",
       "1  12138936         20250       1.00        0.00         1.00        NaN   \n",
       "2  12181264         18000       0.00        0.00         1.00       0.00   \n",
       "3  12188929         15750       0.00        0.00         1.00       1.00   \n",
       "4  12133385         33750       1.00        0.00         1.00       0.00   \n",
       "\n",
       "   Child_Count Credit_Amount Loan_Annuity Accompany_Client  ...  \\\n",
       "0         0.00      61190.55      3416.85            Alone  ...   \n",
       "1         0.00         15282      1826.55            Alone  ...   \n",
       "2         1.00      59527.35       2788.2            Alone  ...   \n",
       "3         0.00       53870.4      2295.45            Alone  ...   \n",
       "4         2.00      133988.4      3547.35            Alone  ...   \n",
       "\n",
       "  Client_Permanent_Match_Tag Client_Contact_Work_Tag       Type_Organization  \\\n",
       "0                        Yes                     Yes           Self-employed   \n",
       "1                        Yes                     Yes              Government   \n",
       "2                        Yes                     Yes           Self-employed   \n",
       "3                        Yes                     Yes                     XNA   \n",
       "4                        Yes                     Yes  Business Entity Type 3   \n",
       "\n",
       "  Score_Source_1 Score_Source_2 Score_Source_3 Social_Circle_Default  \\\n",
       "0           0.57           0.48            NaN                  0.02   \n",
       "1           0.56           0.22            NaN                   NaN   \n",
       "2            NaN           0.55           0.33                  0.07   \n",
       "3            NaN           0.14           0.63                   NaN   \n",
       "4           0.51           0.30           0.36                  0.20   \n",
       "\n",
       "  Phone_Change Credit_Bureau Default  \n",
       "0        63.00           NaN       0  \n",
       "1          NaN           NaN       0  \n",
       "2       277.00          0.00       0  \n",
       "3      1700.00          3.00       0  \n",
       "4       674.00          1.00       0  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoloan_raw_df = pd.read_csv(file_path_1,encoding='unicode_escape') \n",
    "autoloan_raw_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c916028",
   "metadata": {},
   "source": [
    "There are 121856 rows and 40 variables in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "5f8b4cca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 121856 entries, 0 to 121855\n",
      "Data columns (total 40 columns):\n",
      " #   Column                      Non-Null Count   Dtype  \n",
      "---  ------                      --------------   -----  \n",
      " 0   ID                          121856 non-null  int64  \n",
      " 1   Client_Income               118249 non-null  object \n",
      " 2   Car_Owned                   118275 non-null  float64\n",
      " 3   Bike_Owned                  118232 non-null  float64\n",
      " 4   Active_Loan                 118221 non-null  float64\n",
      " 5   House_Own                   118195 non-null  float64\n",
      " 6   Child_Count                 118218 non-null  float64\n",
      " 7   Credit_Amount               118224 non-null  object \n",
      " 8   Loan_Annuity                117044 non-null  object \n",
      " 9   Accompany_Client            120110 non-null  object \n",
      " 10  Client_Income_Type          118155 non-null  object \n",
      " 11  Client_Education            118211 non-null  object \n",
      " 12  Client_Marital_Status       118383 non-null  object \n",
      " 13  Client_Gender               119443 non-null  object \n",
      " 14  Loan_Contract_Type          118205 non-null  object \n",
      " 15  Client_Housing_Type         118169 non-null  object \n",
      " 16  Population_Region_Relative  116999 non-null  object \n",
      " 17  Age_Days                    118256 non-null  object \n",
      " 18  Employed_Days               118207 non-null  object \n",
      " 19  Registration_Days           118242 non-null  object \n",
      " 20  ID_Days                     115888 non-null  object \n",
      " 21  Own_House_Age               41761 non-null   float64\n",
      " 22  Mobile_Tag                  121856 non-null  int64  \n",
      " 23  Homephone_Tag               121856 non-null  int64  \n",
      " 24  Workphone_Working           121856 non-null  int64  \n",
      " 25  Client_Occupation           80421 non-null   object \n",
      " 26  Client_Family_Members       119446 non-null  float64\n",
      " 27  Cleint_City_Rating          119447 non-null  float64\n",
      " 28  Application_Process_Day     119428 non-null  float64\n",
      " 29  Application_Process_Hour    118193 non-null  float64\n",
      " 30  Client_Permanent_Match_Tag  121856 non-null  object \n",
      " 31  Client_Contact_Work_Tag     121856 non-null  object \n",
      " 32  Type_Organization           118247 non-null  object \n",
      " 33  Score_Source_1              53021 non-null   float64\n",
      " 34  Score_Source_2              116170 non-null  float64\n",
      " 35  Score_Source_3              94935 non-null   object \n",
      " 36  Social_Circle_Default       59928 non-null   float64\n",
      " 37  Phone_Change                118192 non-null  float64\n",
      " 38  Credit_Bureau               103316 non-null  float64\n",
      " 39  Default                     121856 non-null  int64  \n",
      "dtypes: float64(15), int64(5), object(20)\n",
      "memory usage: 37.2+ MB\n"
     ]
    }
   ],
   "source": [
    "autoloan_raw_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3756e770",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BIKE = BIKE.astype({\"season_1\":'category', \"temp\":'int64'}) \n",
    "#autoloan_raw_df = autoloan_raw_df.astype ({\"Credit_Amount\":'float', \"Loan_Annuity\":'float'})\n",
    "autoloan_raw_df['Client_Income'] = pd.to_numeric(autoloan_raw_df['Client_Income'], errors='coerce')\n",
    "autoloan_raw_df['Credit_Amount'] = pd.to_numeric(autoloan_raw_df['Credit_Amount'], errors='coerce')\n",
    "autoloan_raw_df['Loan_Annuity'] = pd.to_numeric(autoloan_raw_df['Loan_Annuity'], errors='coerce')\n",
    "autoloan_raw_df['Age_Days'] = pd.to_numeric(autoloan_raw_df['Age_Days'], errors='coerce')\n",
    "autoloan_raw_df['Employed_Days'] = pd.to_numeric(autoloan_raw_df['Employed_Days'], errors='coerce')\n",
    "autoloan_raw_df['Registration_Days'] = pd.to_numeric(autoloan_raw_df['Registration_Days'], errors='coerce')\n",
    "autoloan_raw_df['ID_Days'] = pd.to_numeric(autoloan_raw_df['ID_Days'], errors='coerce')\n",
    "#autoloan_raw_df[] = autoloan_raw_df[].astype()\n",
    "#autoloan_raw_df[] = autoloan_raw_df[].astype()\n",
    "#autoloan_raw_df[] = autoloan_raw_df[].astype()\n",
    "#autoloan_raw_df[] = autoloan_raw_df[].astype()\n",
    "#autoloan_raw_df[] = autoloan_raw_df[].astype()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5e2d09",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "autoloan_raw_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8650bc",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "autoloan_raw_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3013f204",
   "metadata": {},
   "source": [
    "# 2.2 Data Undestanding and Identifying Features and Target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee970058",
   "metadata": {},
   "source": [
    "Once the data is loaded into a pandas dataframe, the next step is identifying which columns represent features and which column represents the target. In this project, we are going to focus on classifying whether loans is defaulted using data collected from a project competition in Hackathon platform via kaggle, which can be found from this link.\n",
    "https://www.kaggle.com/datasets/saurabhbagchi/dish-network-hackathon?select=Test_Dataset.csv\n",
    "\n",
    "The page provides two datasets, TrainDataset and TestDataset. This model building is to be done on TrainDataset. Testdataset from the link isnt used as ['Default'] data is missing. \n",
    "\n",
    "In the test_train split section, we are going to assign X to be the features and y to be the target, which is the ['Default'] variable. Also, this is an  inbalanced dataset, around 8% loans is defaulted. \n",
    "\n",
    "There is 121856 total rows of data. There is 39 columns of features. The first column respondent_id is a unique and random identifier. The remaining 38 features are described in the data library desceiption. \n",
    "\n",
    "Amount of loan that is defaulted is shown below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6474d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoloan_raw_df['Default'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2da8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoloan_lib_raw_df = pd.read_csv(file_path_2,encoding='unicode_escape') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec5b0c3",
   "metadata": {},
   "source": [
    "Data library description is shown as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080b01ee",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# let's take a look of the meaning of each columns\n",
    "def left_align(df: DataFrame):\n",
    "    left_aligned_df = df.style.set_properties(**{'text-align': 'left'})\n",
    "    left_aligned_df = left_aligned_df.set_table_styles(\n",
    "        [dict(selector='th', props=[('text-align', 'left')])]\n",
    "    )\n",
    "    return left_aligned_df\n",
    "left_align(autoloan_lib_raw_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03060b8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e09b6e8",
   "metadata": {},
   "source": [
    "# Initial Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d862ea",
   "metadata": {},
   "source": [
    "Let's drop some unused feature. ID isnt going to be useful for the analysis. Own_house_Age, Social_Circle_Default','Score_Source_1','Score_Source_3' miss too many data, so they are going to be dropped. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e363f599",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoloan_raw_df = autoloan_raw_df.drop(columns=['ID','Own_House_Age','Social_Circle_Default','Score_Source_1','Score_Source_2''Score_Source_3'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c5d58f",
   "metadata": {},
   "source": [
    "Datatype changing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aca3d48",
   "metadata": {},
   "source": [
    "Convert the following variabrles into numerical vairables. They are in object datatype because of missing value. Changing them into numerical form makes it easy to build the pipeline later, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35870944",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoloan_raw_df['Client_Income'] = pd.to_numeric(autoloan_raw_df['Client_Income'], errors='coerce')\n",
    "autoloan_raw_df['Credit_Amount'] = pd.to_numeric(autoloan_raw_df['Credit_Amount'], errors='coerce')\n",
    "autoloan_raw_df['Loan_Annuity'] = pd.to_numeric(autoloan_raw_df['Loan_Annuity'], errors='coerce')\n",
    "autoloan_raw_df['Age_Days'] = pd.to_numeric(autoloan_raw_df['Age_Days'], errors='coerce')\n",
    "autoloan_raw_df['Employed_Days'] = pd.to_numeric(autoloan_raw_df['Employed_Days'], errors='coerce')\n",
    "autoloan_raw_df['Registration_Days'] = pd.to_numeric(autoloan_raw_df['Registration_Days'], errors='coerce')\n",
    "autoloan_raw_df['ID_Days'] = pd.to_numeric(autoloan_raw_df['ID_Days'], errors='coerce')\n",
    "autoloan_raw_df['Population_Region_Relative'] = pd.to_numeric(autoloan_raw_df['Population_Region_Relative'], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ec3280",
   "metadata": {},
   "source": [
    "Convert the following variabrles into 'object type'. Despite being in integer form, we are going to convert it to object because these are categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a23d2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoloan_raw_df['Application_Process_Day'] = autoloan_raw_df['Application_Process_Day'].astype('object')\n",
    "autoloan_raw_df['Application_Process_Hour'] = autoloan_raw_df['Application_Process_Hour'].astype('object')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab6ad42",
   "metadata": {},
   "source": [
    "Convert the following categorical variabrles into 0 and 1, and it will make it easier to build the pipeline later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b15227",
   "metadata": {},
   "outputs": [],
   "source": [
    "#autoloan_raw_df['Client_Gender'].replace({'Male': 0, 'Female': 1, 'XNA': nan}, inplace=True)\n",
    "autoloan_raw_df['Client_Contact_Work_Tag'].replace({'No': 0, 'Yes': 1}, inplace=True) \n",
    "autoloan_raw_df['Client_Permanent_Match_Tag'].replace({'No': 0, 'Yes': 1}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30606ec",
   "metadata": {},
   "source": [
    "Removing Outlier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00fc203",
   "metadata": {},
   "source": [
    "lets look at the distribution of the numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c46fa13",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=4, ncols=7, figsize=(12, 8))\n",
    "\n",
    "numericals = [column for column in autoloan_raw_df.select_dtypes(['int', 'float']).columns]\n",
    "\n",
    "for feature, ax in zip(numericals, axes.flatten()):\n",
    "    ax.hist(autoloan_raw_df[feature], bins=50)\n",
    "    ax.set_title(feature)\n",
    "    \n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6d9c47",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429ba16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoloan_raw_df['Client_Income'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162cfb46",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "autoloan_raw_df['Population_Region_Relative'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afc8106",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoloan_raw_df['Credit_Bureau'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8031058a",
   "metadata": {},
   "outputs": [],
   "source": [
    "upper = autoloan_raw_df.Population_Region_Relative.quantile(.99)\n",
    "upper1 = autoloan_raw_df.Client_Income.quantile(.99)\n",
    "upper2 = autoloan_raw_df.Credit_Bureau.quantile(.99)\n",
    "autoloan_raw_df['Client_Income'] = autoloan_raw_df['Client_Income'].clip(upper=upper1)\n",
    "autoloan_raw_df['Population_Region_Relative'] = autoloan_raw_df['Population_Region_Relative'].clip(upper=upper)\n",
    "autoloan_raw_df['Credit_Bureau'] = autoloan_raw_df['Credit_Bureau'].clip(upper=upper2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4d33a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "autoloan_raw_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0c280c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=4, ncols=7, figsize=(12, 8))\n",
    "\n",
    "numericals = [column for column in autoloan_raw_df.select_dtypes(['int', 'float']).columns]\n",
    "\n",
    "for feature, ax in zip(numericals, axes.flatten()):\n",
    "    ax.hist(autoloan_raw_df[feature], bins=50)\n",
    "    ax.set_title(feature)\n",
    "    \n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9827e745",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "autoloan_raw_df['Credit_Bureau'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a08ec4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "autoloan_raw_df['Population_Region_Relative'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af27512c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "autoloan_raw_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e451cf2",
   "metadata": {},
   "source": [
    "Changing these categorical binary variable into 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d990aadc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "91a0fdfc",
   "metadata": {},
   "source": [
    "Drop Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b743216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoloan_raw_df = autoloan_raw_df.drop(columns=['ID','Own_House_Age','Social_Circle_Default','Score_Source_1','Score_Source_2','Score_Source_3'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8120b41e",
   "metadata": {},
   "source": [
    "Separating data into training and testing sets is an important part of evaluating the models.Most of the data is used for training, and a smaller portion of the data is used for testing. For this analysis: we only split data into train and test. 75% of the data is for training and 25% for test. Also, the data split happened before we even do any EDA analysis to prevent data leakage. There is 91392 row of datas for the train set and 30464 rows of the data for test set before any data cleaning or analysis is done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea73772",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60694a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5661867a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0cea77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0817bf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1866c6e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9a7b6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a58e5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41234be7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740140f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34a7221d",
   "metadata": {},
   "source": [
    "# 4.1 Pre-processing and Exploratory Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f91d881",
   "metadata": {},
   "source": [
    "drop-list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9073ac9f",
   "metadata": {},
   "source": [
    "convert categorical binary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8ddcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train_df.replace({'functional': 0, 'functional needs repair': 1, 'non functional': 2}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd9ae90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#columns_to_drop = ['date_recorded', 'longitude', 'latitude', 'num_private', 'region', 'wpt_name', \n",
    " #                  'subvillage', 'ward', 'recorded_by', 'scheme_management', 'scheme_name', \n",
    " #                  'extraction_type_group', 'extraction_type_class', 'management_group', 'payment', \n",
    " #                  'quality_group', 'quantity_group', 'source_type', 'source_class', 'waterpoint_type_group']\n",
    "\n",
    "#X_train_df.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "# Preview new dataframe\n",
    "#X_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6a3b03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "autoloan_raw_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6fec0b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "missing_fractions = autoloan_raw_df.isnull().mean().sort_values(ascending=False)\n",
    "#missing_fractions = autoloan_raw_df.isnull().mean()\n",
    "missing_fractions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57464c48",
   "metadata": {},
   "source": [
    "There is missing value dataset, and lets f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b50dd70",
   "metadata": {},
   "source": [
    "# 4.1 ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bb1683",
   "metadata": {},
   "source": [
    "Are all the IDs unique?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faca9c38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#autoloan_raw_df['ID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba04eda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = \"{:.2f}\".format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ff54cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#autoloan_raw_df['ID'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc414a40",
   "metadata": {},
   "source": [
    "They are all unique, however ID isnt useful for modeling and is dropped later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17eb600",
   "metadata": {},
   "source": [
    "# 4.2 Income"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad54327",
   "metadata": {},
   "source": [
    "0.03% of Client_Income data has a missing value, and it is going to be replaced by the income average?, which is the most frequency method for the SimpleImputer when we set up the preprocessing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fcdbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoloan_raw_df['Client_Income'] = pd.to_numeric(autoloan_raw_df['Client_Income'], errors='coerce')\n",
    "autoloan_raw_df['Client_Income'] = autoloan_raw_df['Client_Income'].fillna(0)\n",
    "#x_train['Client_Income'] = pd.to_numeric(x_train['Client_Income'], errors='coerce')\n",
    "#x_test['Client_Income'] = pd.to_numeric(x_test['Client_Income'], errors='coerce')\n",
    "\n",
    "#autoloan_raw_df['Client_Income'] = autoloan_raw_df['Client_Income'].fillna(0)\n",
    "#autoloan_raw_df['Client Income'] = autoloan_raw_df['Client_Income'].apply(lambda x: float(x))\n",
    "#autoloan_raw_df['Client Income'] = autoloan_raw_df['Client Income'].astype(float).fillna(autoloan_raw_df['Client Income'].median())\n",
    "#autoloan_raw_df[autoloan_raw_df.columns['Client_Income']] = autoloan_raw_df[autoloan_raw_df.columns['Client_Income']].apply(pd.to_numeric, errors='coerce').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f056418f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "autoloan_raw_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a210b7",
   "metadata": {},
   "source": [
    "3.3 Car_Owned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d258cb7",
   "metadata": {},
   "source": [
    "0.03% of Car_Owned data has a missing value, and it is going to be replaced by the non Car_Owned, which is the most frequency method for the SimpleImputer when we set up the preprocessing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074d083c",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoloan_raw_df['Car_Owned'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501158c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoloan_raw_df['Car_Owned'] = autoloan_raw_df['Car_Owned'].fillna(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8d6620",
   "metadata": {},
   "source": [
    " 3.4 Bike_Owned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530abf49",
   "metadata": {},
   "source": [
    "0.03% of Bike_Owned data has a missing value, and it is going to be replaced by the non Bike_Owned, which is the most frequency method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9ac8af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "autoloan_raw_df['Bike_Owned'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a90ba2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoloan_raw_df['Bike_Owned'] = autoloan_raw_df['Bike_Owned'].fillna(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97b3bfb",
   "metadata": {},
   "source": [
    " 3.5 Active_Loan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082e27f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoloan_raw_df['Active_Loan'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1263f20",
   "metadata": {},
   "source": [
    "0.03% of active loan data has a missing value, and it is going to be replaced by the mean of the default group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efef79ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoloan_raw_df['Active_Loan'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be81da10",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoloan_raw_df['Active_Loan'] = autoloan_raw_df['Active_Loan'].fillna(autoloan_raw_df.groupby('Default')['Active_Loan'].transform('mean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bce515",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "autoloan_raw_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5e5b1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#autoloan_raw_df['Client_Income'] = autoloan_raw_df['Client_Income'].fillna(autoloan_raw_df['Client_Income'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4b5f4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "autoloan_raw_df['Client_Occupation'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d008ed9",
   "metadata": {},
   "source": [
    "3.6 House_Own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9819e5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoloan_raw_df['House_Own'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd440b87",
   "metadata": {},
   "source": [
    "0.03% of active loan data has a missing value, and it is going to be replaced by the mean of the default group."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d533cb9",
   "metadata": {},
   "source": [
    "3.7 Child_Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9042e219",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoloan_raw_df['Child_Count'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4812c91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoloan_raw_df['Client_Occupation'] = autoloan_raw_df['Client_Occupation'].fillna(value ='Other')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7316584e",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoloan_raw_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620cfdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoloan_raw_df['Credit_Amount'] = autoloan_raw_df['Credit_Amount'].fillna(autoloan_raw_df['Credit_Amount'].mean)\n",
    "autoloan_raw_df['Loan_Annuity'] = autoloan_raw_df['Loan_Annuity'].fillna(autoloan_raw_df['Loan_Annuity'].mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c56f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoloan_raw_df['Loan_Annuity'] = autoloan_raw_df['Loan_Annuity'].fillna(autoloan_raw_df['Loan_Annuity'].mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1cd14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoloan_raw_df['Credit_Amount'] = autoloan_raw_df['Credit_Amount'].fillna(autoloan_raw_df['Credit_Amount'].mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782a3a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoloan_raw_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73108b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoloan_raw_df['Client_Income_Type'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b7ef31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "autoloan_raw_df['Client_Education'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1287ff7f",
   "metadata": {},
   "source": [
    "# Test Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471b9454",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = autoloan_raw_df['Default']\n",
    "X = autoloan_raw_df.drop(columns=['Default'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861ec261",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create train-test set using 75%-25% ratio for the train set and test set and set the random state = 42) randomly split the data\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y ,test_size=0.25,stratify=y,random_state=42)\n",
    "# shape of train and test splits\n",
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fdf9f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "921789e0",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29238d1",
   "metadata": {},
   "source": [
    "Now we need to set a pipeline for our data with the imputing staregy from the discussion above. We will set up a numeric pipeline for numerical variable. Feautres with missing value will be imputed by mean. Afterwards, it will be fed into a standard scaler for scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2585693",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b667a8",
   "metadata": {},
   "source": [
    "I am going to make a list of the following categorical variable so I can prepare a list for the feature for the one hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e912ff1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accompany_Client\")\n",
    "print(x_train.Accompany_Client.unique())\n",
    "\n",
    "print(\"Client_Income_Type\")\n",
    "print(x_train.Client_Income_Type.unique())\n",
    "\n",
    "print(\"Client_Education\")\n",
    "print(x_train.Client_Education.unique())\n",
    "\n",
    "print(\"Client_Marital_Status\")\n",
    "print(x_train.Client_Marital_Status.unique())\n",
    "\n",
    "print(\"Client_Gender\")\n",
    "print(x_train.Client_Gender.unique())\n",
    "\n",
    "\n",
    "#print(\"Client_Loan_Contract_Type\")\n",
    "#print(x_train.Client_Loan_Contract_Type.unique())\n",
    "\n",
    "print(\"Client_Housing_Type\")\n",
    "print(x_train.Client_Housing_Type.unique())\n",
    "\n",
    "\n",
    "#print(\"Client_Loan_Contract_Type\")\n",
    "#print(x_train.Client_Loan_Contract_Type.unique())\n",
    "\n",
    "print(\"Cleint_City_Rating\")\n",
    "print(x_train.Cleint_City_Rating.unique())\n",
    "\n",
    "print(\"Client_Education\")\n",
    "print(x_train.Client_Education.unique())\n",
    "\n",
    "print(\"Client_Marital_Status\")\n",
    "print(x_train.Client_Marital_Status.unique())\n",
    "\n",
    "print(\"Client_Occupation\")\n",
    "print(x_train.Client_Occupation.unique())\n",
    "\n",
    "\n",
    "print(\"Client_Contact_Work_Tag\")\n",
    "print(x_train.Client_Contact_Work_Tag.unique())\n",
    "\n",
    "print(\"Client_Permanent_Match_Tag\")\n",
    "print(x_train.Client_Permanent_Match_Tag.unique())\n",
    "\n",
    "print(\"Loan_Contract_Type\")\n",
    "print(x_train.Loan_Contract_Type.unique())\n",
    "\n",
    "print(\"Type_Organization\")\n",
    "print(x_train.Client_Income_Type.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3643d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aba5cf8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Client_Education_list = ['Junior secondary','Secondary','Graduation dropout','Graduation','Post Grad']\n",
    "Client_Marital_Status_list = ['D','W','M','S']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68862f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_Client_Education_pipeline = Pipeline([\n",
    "    ('ordimputer', SimpleImputer(strategy = 'most_frequent')),\n",
    "    ('ordenc', OrdinalEncoder(categories = [Client_Education_list])),\n",
    "    ('ordnorm', StandardScaler())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad5e012",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_Client_Marital_Status_pipeline = Pipeline([\n",
    "    ('ordimputer', SimpleImputer(strategy = 'most_frequent')),\n",
    "    ('ordenc', OrdinalEncoder(categories = [Client_Marital_Status_list])),\n",
    "    ('ordnorm', StandardScaler())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcb096b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nominal_pipeline = Pipeline([\n",
    "    ('onehotimputer', SimpleImputer(strategy = 'most_frequent')),\n",
    "    ('onehotenc', OneHotEncoder(sparse = False, drop = 'first')), \n",
    "    ('onehotnorm', MaxAbsScaler())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c223f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_pipeline = Pipeline([\n",
    "    ('numimputer', SimpleImputer(strategy = 'mean')), \n",
    "    ('numnorm', StandardScaler())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89890275",
   "metadata": {},
   "outputs": [],
   "source": [
    "#class NameDropper (BaseEstimator, TransformerMixin):\n",
    "  #  def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17ce284",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3348f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24d84d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for item in three_per:\n",
    "    #autoloan_raw_df[item] = autoloan_raw_df[item].fillna(0)\n",
    "    #autoloan_raw_df[item] = autoloan_raw_df[item].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc3cdec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e329f66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e25804b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_cols = list(x_train.select_dtypes(['int', 'float']).columns)\n",
    "ohe_cols = list(x_train.select_dtypes('object').columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8ad152",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d07ad8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ca38e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6280034b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = ColumnTransformer(\n",
    "    [ (\"ordinalpipe\", ordinal_Client_Education_pipeline, ['Client_Education']),\n",
    "       (\"ordinalpipe2\", ordinal_Client_Marital_Status_pipeline, ['Client_Marital_Status']),\n",
    "       #(\"ordinalpipe3\", ordinal_emp_status_pipeline, ['employment_status']),\n",
    "       #(\"ordinalpipe4\", ordinal_edu_pipeline, ['education']),\n",
    "       #(\"ordinalpipe5\", ordinal_census_pipeline, ['census_msa']),\n",
    "       #(\"ordinalpipe6\", ordinal_hhs_pipeline, ['hhs_geo_region']),\n",
    "       (\"nominalpipe\", nominal_pipeline,ohe_cols),\n",
    "       #(\"nominalpipe2\", nominal_insurance_pipeline,['health_insurance']),\n",
    "       #(\"nominalpipe3\", nominal_doc_rec_pipeline,['doctor_recc_h1n1']),\n",
    "       (\"numpipe\", numeric_pipeline, num_cols)])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613e417f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_clean = pd.DataFrame(ct.fit_transform(x_train))\n",
    "x_train_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9168d792",
   "metadata": {},
   "source": [
    "# Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd540d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps=[('preprocessing', ct), \n",
    "       ('classifier', DummyClassifier(strategy='most_frequent'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac4dba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_pipe = Pipeline(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28514043",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_pipe.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa78f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred0= baseline_pipe.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc49cc1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "status_labels = ['0: Normal', '1: Default']\n",
    "plot_confusion_matrix(baseline_pipe,x_test,y_test,display_labels = status_labels)\n",
    "plt.grid(False)\n",
    "plt.title('Confusion Matrix - Baseline')\n",
    "plt.show()\n",
    "\n",
    "baseline_classification_report = classification_report(y_test, y_pred0)\n",
    "print(baseline_classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e266877d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(baseline_pipe.score(x_train,y_train))\n",
    "print(baseline_pipe.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1897ad20",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [('preprocess', ct),\n",
    "            ('logreg',\n",
    "                       LogisticRegression(random_state=42))]\n",
    "\n",
    "model1_pipe = Pipeline(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db8055f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_pipe.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d38616",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model1_pipe.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526bcdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_test,y_pred) * 100\n",
    "print('Accuracy is :{0}'.format(acc))\n",
    "\n",
    "pre = precision_score(y_test,y_pred) * 100\n",
    "print('precision is :{0}'.format(pre))\n",
    "\n",
    "# Check the AUC for predictions\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "print('\\nAUC is :{0}'.format(round(roc_auc, 2)))\n",
    "\n",
    "# Create and print a confusion matrix \n",
    "print('\\nConfusion Matrix')\n",
    "print('----------------')\n",
    "#pd.crosstab(y_test, y_pred, rownames=['True'], colnames=['Predicted'], margins=True)\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "\n",
    "plot_confusion_matrix(model1_pipe,x_test,y_test,display_labels = status_labels)\n",
    "plt.grid(False)\n",
    "plt.title('Confusion Matrix - Linera Regression ')\n",
    "plt.show()\n",
    "logreg_classification_report = classification_report(y_test, y_pred)\n",
    "print(logreg_classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bf2a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model1_pipe.score(x_train,y_train))\n",
    "print(model1_pipe.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078eed1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1636be23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16230497",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4871ff0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ordi =OrdinalEncoder(categories=[Client_Education_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47df91ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train['Client_Education'] = x_train['Client_Education'].fillna(value = 'Secondary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94352ca0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568408fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a0e43e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0a5e73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83cf7ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91714832",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ordi.fit(x_train[['Client_Education']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7621ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train['Client_Education']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c030d0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(ordi.transform(x_train[['Client_Education']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5710265b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c09289",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
